# 1 Prelude

!!! tip "å‰è¨€"
    æœ¬ç« å†…å®¹æœ‰ä¸å°‘æ¦‚è¿°æ€§çš„å†…å®¹ï¼Œå¾ˆå¤šå†…å®¹å¾ˆæµ…ä¹Ÿå¾ˆæ•£ï¼Œä¹‹åç« èŠ‚éƒ½ä¼šè¯¦ç»†å±•å¼€ï¼Œæ­¤å¤„æ›´å¤šçš„æ˜¯ä»‹ç»ã€‚å»ºè®®é‡ç‚¹å…³æ³¨ä»¥ä¸‹éƒ¨åˆ†ï¼š

    - [1.1 Eight Great Ideas](#11-eight-great-ideas)
    - [1.5 Performance](#15-performance)

- å†¯Â·åŒä¼Šæ›¼æ¶æ„
  - è®¡ç®—ä¸å­˜å‚¨åˆ†ç¦»
  - æ•°æ®å’ŒæŒ‡ä»¤æ”¾åœ¨åŒä¸€ä¸ªå­˜å‚¨å™¨

<center>
    ![](2023-06-23_12-05-34.png)
</center>

```mermaid
graph LR;
A["Computer\nSystem"]
B["Software"]
C["Hardware"]
D["CPU"]
E["Memory"]
F["I/O\ninterface"]
G["Control\nunit"]
H["Datapath"]

A--->B
A--->C
C--->D
C--->E
C--->F
D--->G
D--->H
```


## 1.1 Eight Great Ideas

éƒ¨åˆ†åœ¨å®é™…é¢˜ç›®ä¸­è¿˜æŒºéš¾åŒºåˆ†çš„ï¼Œæ³¨æ„è¯†åˆ«é¢˜ç›®ä¸­çš„å…³é”®æš—ç¤ºã€‚æ­¤å¤–ï¼Œå…ˆå­¦ä¹ äº†ä¹‹åçš„å†…å®¹ä¼šå¯¹éƒ¨åˆ†æ€æƒ³æœ‰æ›´æ·±åˆ»çš„ç†è§£ã€‚

- Design for Mooreâ€™s Law ï¼ˆè®¾è®¡ç´§è·Ÿæ‘©å°”å®šå¾‹ï¼‰
    - **Moore's Law**: Integrated circuit resources double every 18-24 months.
    - Design for where it will be when finishes rather than design for where it starts.
- Use Abstraction to Simplify Design (é‡‡ç”¨æŠ½è±¡ç®€åŒ–è®¾è®¡)
    - å±‚æ¬¡åŒ–ã€æ¨¡å—åŒ–çš„è®¾è®¡
- Make the Common Case Fast (åŠ é€Ÿå¤§æ¦‚ç‡äº‹ä»¶)
- Performance via Parallelism (é€šè¿‡å¹¶è¡Œæé«˜æ€§èƒ½)
- Performance via Pipelining (é€šè¿‡æµæ°´çº¿æé«˜æ€§èƒ½)
    - æ¢å¥è¯è¯´å°±æ˜¯ï¼Œæ¯ä¸ªæµç¨‹åŒæ—¶è¿›è¡Œï¼Œåªä¸è¿‡æ¯ä¸€ä¸ªæµç¨‹å·¥ä½œçš„å¯¹è±¡æ˜¯æ—¶é—´ä¸Šç›¸é‚»çš„è‹¥å¹²äº§å“ï¼›
    - ç›¸æ¯”äºç­‰ä¸€ä¸ªäº§å“å®Œå…¨ç”Ÿäº§å®Œå†å¼€å§‹ä¸‹ä¸€ä¸ªäº§å“çš„ç”Ÿäº§ï¼Œä¼šå¿«å¾ˆå¤šï¼›
    - å¸Œæœ›æ¯ä¸€ä¸ªæµç¨‹çš„æ—¶é—´æ˜¯ç›¸å¯¹å‡åŒ€çš„ï¼›
- Performance via Prediction (é€šè¿‡é¢„æµ‹æé«˜æ€§èƒ½)
    - ä¾‹å¦‚å…ˆå½“ä½œ `if()` æ¡ä»¶æˆç«‹ï¼Œæ‰§è¡Œå®Œå†…éƒ¨å†…å®¹ï¼Œå¦‚æœåæ¥å‘ç°ç¡®å®æˆç«‹ï¼Œé‚£ä¹ˆç›´æ¥ applyï¼Œå¦åˆ™å°±å†é‡æ–°æ­£å¸¸åšï¼›
    - è¿™ä¹ˆåšå°±å¥½åœ¨ï¼ˆåˆæˆ–è€…è¯´åªæœ‰è¿™ç§æƒ…å†µé€‚åˆé¢„æµ‹ï¼‰ï¼Œé¢„æµ‹æˆåŠŸäº†å°±åŠ é€Ÿäº†ï¼Œé¢„æµ‹å¤±è´¥äº†çº æ­£çš„æˆæœ¬ä¹Ÿä¸é«˜ï¼› 
- Hierarchy of Memories (å­˜å‚¨å™¨å±‚æ¬¡)
    - Disk / Tape -> Main Memory(DRAM) -> L2-Cache(SRAM) -> L1-Cache(On-Chip) -> Registers
- Dependability via Redundancy (é€šè¿‡å†—ä½™æé«˜å¯é æ€§)
    - ç±»ä¼¼äºå¡è½¦çš„å¤šä¸ªè½®èƒï¼Œä¸€ä¸ªæ¨¡å— down äº†ä»¥åä¸ä¼šå‰§çƒˆå½±å“æ•´ä¸ªç³»ç»Ÿï¼›

---

## 1.2 Below Program

```mermaid
graph TD;
A["High-level language program"]
B["Assembly language program"]  
C["Binary machine language"]
A --->|"Compiler"| B --->|"Assembler"| C 
```

- é«˜çº§è¯­è¨€çš„å‡ºç°ä½“ç°äº†â€œæŠ½è±¡â€çš„æ€æƒ³ï¼›

---

## 1.3 Components of a computer

The five classic components of a computer:

- **input**;
- **output**;
- **memory** (DRAM);
    - ç¨‹åºã€æ•°æ®å­˜å‚¨çš„åœ°æ–¹ï¼Œä¹Ÿæ˜¯ç¨‹åºâ€œè¿è¡Œçš„ä½ç½®â€ï¼›
    - cache memory (SRAM): buffer for the DRAM memory;
- **datapath**;
    - è´Ÿè´£å®é™…çš„æ•°æ®å¤„ç†ï¼›
- **control**;
    - è´Ÿè´£æŒ‡æŒ¥æ§åˆ¶å¦‚ä½•è¿›è¡Œæ•°æ®å¤„ç†ï¼Œç»™å‡ºæ§åˆ¶ä¿¡å·ï¼›

> **processor** / **(central processor unit)CPU** = datapath + control

ä¸ºäº†å®ç°æŠ½è±¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€å¥—ç¡¬ä»¶å’Œæœ€ä½æŠ½è±¡ç¨‹åº¦çš„è½¯ä»¶ä¹‹é—´çš„æ¥å£â€”â€”**instruction set architecture** (ISA)ï¼Œæœ¬è¯¾ç¨‹å°†ä¼šä»¥ RISC-V ä¸ºä¾‹è¿›è¡Œä»‹ç»ï¼Œè¯¦ç»†å†…å®¹å°†æ”¾åœ¨[ç¬¬äºŒç« ](./2_instructions.md)ã€‚

æ­¤å¤–ï¼Œæ ¹æ®æ˜¯å¦å…·æœ‰æ˜“å¤±æ€§ï¼Œå†…å­˜è¢«åˆ†ä¸ºä¸¤ç±»ï¼š**main memory / prime memory** (eg. DRAM) å’Œ **secondary memory** (eg. magnetic disks, flash memory)ã€‚

---

## 1.4 Technologies for Building Processors and Memory

- integrated circuit (IC): dozens to hundreds of transistors into a single chip;
- very large-scale integrated circuit (VLIC): billions of combinations of conductors, insulators, and switches manufactured in a single small package;

é›†æˆç”µè·¯åŠ å·¥ç»•ä¸å¼€çš„ä¸€ä¸ªè¯é¢˜å°±æ˜¯ç¡…æ™¶åŠ å·¥ï¼Œç¡…æ™¶é”­(silicon crystal ingot)ä¼šè¢«åŠ å·¥æˆç¡…ç‰‡(silicon wafer)ï¼Œç„¶åå†è¿›è¡ŒåŠ å·¥ï¼Œæœ€åæˆä¸ºé›†æˆç”µè·¯ã€‚ä¸€ä¸ªç¡…ç‰‡ä¼šè¢«åˆ‡æˆå¾ˆå¤šå°å—ï¼Œå…¶ä¸­éš¾å…æœ‰ä¸€äº›åçš„(defects)ï¼Œè€Œé‚£äº›å¥½çš„å°±è¢«ç§°ä¸º diesï¼Œæˆ–è€…è¯´ chipsã€‚è€Œè¿™ä¸ªå·¥è‰ºçš„äº§é‡åˆ™ç”±ä¸‹é¢è¿™ä¸ªå…¬å¼å®šä¹‰ï¼š

$$
\begin{aligned}
\text{Cost per die} &= \frac{\text{Cost per wafer}}{\text{Dies per wafer} \times \text{yield}} \\
\text{Dies per wafer} &\approx \frac{\text{Wafer area}}{\text{Die area}} \\
\text{Yield} &= \frac{1}{\left(
    1 + (\text{Defects per area} \times \text{Die area} / 2)
\right) ^ 2}
\end{aligned}
$$

æœ€åä¸€ä¸ªå¼å­åŸºäºç»éªŒè§‚å¯Ÿå¾—åˆ°ï¼Œå…¶ä¸­æŒ‡æ•°å®é™…ä¸Šä¸åŠ å·¥æ­¥éª¤æ•°é‡æœ‰å…³ã€‚

---

## 1.5 Performance

è¡¡é‡è®¡ç®—æœºçš„æ€§èƒ½å’Œè¡¨ç°ï¼Œæ— è®ºå¯¹äºå·¥ç¨‹å¸ˆè¿˜æ˜¯æ¶ˆè´¹è€…éƒ½æ˜¯ä¸€ä¸ªéå¸¸å¿…è¦çš„éœ€æ±‚ã€‚å…¶ä¸­ä¸€ä¸ªé‡è¦çš„æ ‡å‡†å°±æ˜¯â€œè¿è¡Œé€Ÿåº¦â€ï¼Œå…·ä½“æ¥è¯´ï¼š

- **Response Time / Execution Time**	ä»ç¨‹åºå¼€å§‹åˆ°ç»“æŸçš„æ—¶é—´
- **Throughput / Bandwidth**	å•ä½æ—¶é—´å†…å®Œæˆçš„ä»»åŠ¡æ•°é‡

å¹¶ä¸”æˆ‘ä»¬è¿™æ ·è”ç³» performance å’Œ execution timeï¼š

$$
\text{Performance}_X = \frac{1}{\text{Execution time}_X}
$$

è€Œç›¸å¯¹æ€§èƒ½(Relative Performance)å°±æ˜¯éå¸¸ naive åœ°å¯¹ä¸¤ä¸ªæ¯”è¾ƒå¯¹è±¡æ±‚æ¯”å€¼ï¼Œæˆ‘ä»¬é€šå¸¸æ‰€è¯´çš„æ¯”è¾ƒä¸¤ä¸ªä¸œè¥¿çš„æ€§èƒ½ï¼Œä¹Ÿå°±æ˜¯æŒ‡è®¡ç®—å®ƒä»¬çš„ç›¸å¯¹æ€§èƒ½ã€‚

å½“æˆ‘ä»¬éœ€è¦è¡¡é‡ä¸€ä¸ª CPU çš„æ€§èƒ½ï¼Œæˆ–è€…å…·ä½“å»åˆ†æä¸€ä¸ª CPU çš„æ€§èƒ½æ„æˆæ—¶ï¼Œå°±éœ€è¦æ›´åŠ å…·ä½“çš„æŒ‡æ ‡ï¼š

- CPU (execution) timeï¼ˆCPU æ‰§è¡Œæ—¶é—´ï¼‰
- CPU clock cycleï¼ˆæ—¶é’Ÿå‘¨æœŸæ•°ï¼‰
- clock rateï¼ˆæ—¶é’Ÿé¢‘ç‡ï¼‰ / clock cycle timeï¼ˆæ—¶é’Ÿå‘¨æœŸï¼‰

$$
\begin{aligned}
    \text{CPU execution time} &= \text{CPU clock cycles} \times \text{Clock cycle time} \\
    &= \frac{\text{CPU clock cycles}}{\text{Clock rate}}
\end{aligned}
$$

åŒæ—¶ï¼Œè¿˜æœ‰ä¸€ä¸ªå®¹æ˜“å¾—åˆ°çš„å…³ç³»ï¼š

$$
\begin{aligned}
    \text{CPU clock cycles} &= \text{Instructions count} \times \text{Average cycles per instruction}
\end{aligned}
$$

å…¶ä¸­ï¼Œæ¯æ¡æŒ‡ä»¤çš„å¹³å‡å‘¨æœŸæ•°(Average cycles per instruction)åˆç¼©å†™ä¸º CPIã€‚

> CPI(clock cycles per instruction), the average number of clock cycles each instruction takes to execute = $\frac{\text{CPU clock cycles}}{\text{Instruction count}}$;

äºæ˜¯ï¼Œå°†ä¸Šé¢çš„ä¸¤å—å…³ç³»æ•´åˆèµ·æ¥å°±å¾—åˆ°ï¼š

$$
\begin{aligned}
    \text{CPU time} &= \text{Instruction count} \times \text{CPI} \times \text{Clock cycle time} \\ 
    &= \frac{\text{Instruction count} \times \text{CPI}}{\text{Clock rate}}
\end{aligned}
$$

??? note "ç»ƒä¹ "
    === "é¢˜é¢"
        ç¼–è¯‘å™¨å¯èƒ½æä¾›ä¸¤ç§ä»£ç åºåˆ—ï¼Œæ¯ä¸€ä¸ªåºåˆ—éƒ½åŒ…å« Aã€Bã€C ä¸‰ç§ç±»å‹çš„æŒ‡ä»¤ï¼Œæ¯ç§æŒ‡ä»¤çš„ CPI å¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚

        |     |  A  |  B  |  C  |   
        |:---:|:---:|:---:|:---:|
        | CPI |  1  |  2  |  3  |
        |Instruction count \@ seq 1|  2  |  1  |  2  |
        |Instruction count \@ seq 2|  4  |  1  |  1  |

        1. å“ªä¸€ä¸ª seq æ‰§è¡Œäº†æœ€å¤šçš„æŒ‡ä»¤ï¼Ÿ
        2. å“ªä¸€ä¸ª seq æ›´å¿«ï¼Ÿ
        3. æ¯ä¸€ä¸ª seq çš„ CPI æ˜¯å¤šå°‘ï¼Ÿ

    === "ç­”æ¡ˆ"

        1.å¼±æ™ºé¢˜ï¼ŒåŠ èµ·æ¥å°±è¡Œã€‚

        $$
        \begin{aligned}
            \text{instruction count @ seq 1} = 2 + 1 + 2 = 5 \\
            \text{instruction count @ seq 2} = 4 + 1 + 1 = 6
        \end{aligned}
        $$

        æ‰€ä»¥ 2 å¤šã€‚

        2.ç”±äºäº§ç”Ÿå·®å¼‚çš„åœ°æ–¹æ˜¯ç¼–è¯‘å™¨ï¼Œæ‰€ä»¥æˆ‘ä»¬é»˜è®¤æ—¶é’Ÿå‘¨æœŸç›¸åŒï¼Œæ‰€ä»¥æ¯”è¾ƒ CPU time ç­‰æ•ˆäºæ¯”è¾ƒ clock cyclesã€‚

        $$
        \begin{aligned}
            \text{clock cycles @ seq 1} = 2 \times 1 + 1 \times 2 + 2 \times 3 = 10 \\
            \text{clock cycles @ seq 2} = 4 \times 1 + 1 \times 2 + 1 \times 3 = 9
        \end{aligned}
        $$

        æ‰€ä»¥ 2 å¿«ã€‚

        3.seq çš„ CPI å°±æ˜¯ seq çš„ clock cycles é™¤ä»¥ seq çš„ instruction countï¼š

        $$
        \begin{aligned}
              \text{CPI @ seq 1} = \frac{10}{5} = 2 \\
              \text{CPI @ seq 2} = \frac{9}{6} = 1.5
        \end{aligned}
        $$

??? note "ç»ƒä¹ "
    === "é¢˜é¢"
        A given application written in Java runs 15 seconds on a desktop processor. A new  Java compiler is released that requires only 0.6 as many instructions as the old  compiler. Unfortunately, it increases the CPI by 1.1. How fast can we expect the application to run using this new compiler? Pick the right answer from the three  choices below:

        1. $\frac{15\times 0.6}{1.1} = 8.2 sec$;
        2. $15\times 0.6\times 1.1 = 9.9 sec$;
        3. $\frac{15\times 1.1}{0.6} = 27.5 sec$;
        
    === "ç­”æ¡ˆ"
        å·²çŸ¥å…¬å¼ï¼š

        $$
        \begin{aligned}
            \text{CPU time} &= \text{CPI} * \text{instruction count} * \text{clock cycle time}
        \end{aligned}
        $$

        ç°åœ¨ CPI å˜æˆ 1.1 å€ï¼Œinstruction count å˜æˆ 0.6 å€ï¼Œæ‰€ä»¥åº”è¯¥é€‰ 2ã€‚
        

---

## Others

- â€¦â€¦ä¸æ˜¯å¾ˆæƒ³å­¦äº† å†è¯´å§

- $KB = 10^3 B, KiB = 2^{10} B$
- K M G T P E Z Y
- **Amdahl Law**   $T_{\text{improved}} = \cfrac{T_{\text{affected}}}{\text{Improvement Factor}}+T_\text{unaffected}$ [ğŸ”— Wiki](https://zh.wikipedia.org/wiki/%E9%98%BF%E5%A7%86%E8%BE%BE%E5%B0%94%E5%AE%9A%E5%BE%8B)

- MIPS: Millions of Instructions Per Seconds

$$
\begin{aligned}
MIPS 
&= \frac{\text{\#Instructions}}{\text{Execution time} \times 10^6} \\
&= \frac{\text{\#Instructions}}{
    \frac{
        \text{Instruction count} \times \text{CPI}
    }{
        \text{Clock rate}
    } \times 10^6
} \\
&= \frac{\text{Clock rate}}{\text{CPI} \times 10^6}
    
\end{aligned}
$$

### å†…å­˜

<center>
    ![](2023-06-23_17-12-24.png)
</center>
